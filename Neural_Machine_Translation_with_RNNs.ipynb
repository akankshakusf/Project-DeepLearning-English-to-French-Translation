{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akankshakusf/Project-DeepLearning-English-to-French-Translation/blob/master/Neural_Machine_Translation_with_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "45CHLgAvuG-q"
      },
      "outputs": [],
      "source": [
        "#import ML packages\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "from sklearn.metrics import confusion_matrix,roc_curve\n",
        "import pathlib\n",
        "import io\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "\n",
        "#import DL package\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer,Dense, Flatten, InputLayer, BatchNormalization, Bidirectional, Dropout, Input, Embedding, TextVectorization\n",
        "from tensorflow.keras.layers import SimpleRNN, Conv1D, LSTM, GRU\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy, TopKCategoricalAccuracy, TopKCategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "mIsUJ6KO0ir8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Download"
      ],
      "metadata": {
        "id": "hNKV6ywY0tHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ],
      "metadata": {
        "id": "odODFPY10r0O",
        "outputId": "08e21938-546a-465d-e423-3e1640abc79d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-22 10:29:32--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7943074 (7.6M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.57M  5.13MB/s    in 1.5s    \n",
            "\n",
            "2025-04-22 10:29:35 (5.13 MB/s) - ‘fra-eng.zip’ saved [7943074/7943074]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "id": "3OB777Yd0rw-",
        "outputId": "1293d2fa-b959-4b83-8215-31547e363ef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Dataset"
      ],
      "metadata": {
        "id": "Tm-6-2710xV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d dhruvildave/en-fr-translation-dataset"
      ],
      "metadata": {
        "id": "83td25ws0ZCE",
        "outputId": "11d1b7c4-79ea-4ec8-8450-cf23e4b0dcde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset\n",
            "License(s): ODbL-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/en-fr-translation-dataset.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "id": "AxPKfUkE5TQ0",
        "outputId": "611c9f93-71f8-4bdb-dc95-3a4a9f1f01c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/en-fr-translation-dataset.zip\n",
            "  inflating: /content/dataset/en-fr.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.experimental.CsvDataset(\n",
        "  \"/content/dataset/en-fr.csv\",\n",
        "  [\n",
        "    tf.string,\n",
        "    tf.string\n",
        "  ],\n",
        ")"
      ],
      "metadata": {
        "id": "qYAbSuXo0w7j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "qj-M9VE86GlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"
      ],
      "metadata": {
        "id": "2THpKCsm0w4s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#review dataset\n",
        "for i in text_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "ulVcvBdT0mPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625d1c1f-5fbf-43a4-da3a-7d16afb5ca66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #lets skip a max number of records and check what max length we find\n",
        "# for i in text_dataset.skip(190000):\n",
        "#   print(len(tf.strings.split(i,\" \")))"
      ],
      "metadata": {
        "id": "vKU9oT6S0mM1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Since i saw that the max len of the sentence is 107. I am going to go ahead with a sequence length of 64 as we also have french letters"
      ],
      "metadata": {
        "id": "Xd0sx_-MuuLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE= 20000\n",
        "ENGLISH_SEQUENCE_LENGTH=64\n",
        "FRENCH_SEQUENCE_LENGTH=64\n",
        "EMBEDDING_DIM = 300\n",
        "BATCH_SIZE=64"
      ],
      "metadata": {
        "id": "--NXDb7RxLV-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create vectorizer layer to create vectors\n",
        "- reference :https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization"
      ],
      "metadata": {
        "id": "wtM_PoJpxYyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn text to lowercase and remove punctuation\n",
        "# Keep only top VOCAB_SIZE words\n",
        "# Convert words to numbers\n",
        "# Make all sentences the same length"
      ],
      "metadata": {
        "id": "jWdoHy9O5pLS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vectorize_layer = TextVectorization (\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length = ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "Gj-ZQvGRxem2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer = TextVectorization (\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length = FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "1zXDZOlExekR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Look at this sample data from dataset and get rid of tabs--->  \\t\n",
        "'Go.\\tVa !\\tCC-BY 2.0 (France)"
      ],
      "metadata": {
        "id": "VG1V7ioQ0UxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def selector (input_text):\n",
        "  split_text=tf.strings.split(input_text, '\\t') ##after splitting collect english and french separately\n",
        "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
      ],
      "metadata": {
        "id": "3X50IU-w0hfV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map text_dataset to selector above function\n",
        "split_dataset = text_dataset.map(selector)  ## this is for final dataset"
      ],
      "metadata": {
        "id": "dr5LdXgK1IZl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separator(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken' #final output"
      ],
      "metadata": {
        "id": "kRklWiwAzs3V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map text_dataset to selector above function\n",
        "init_dataset = text_dataset.map(separator)  ## this is for just intermediated start-end token consideration"
      ],
      "metadata": {
        "id": "gtiK2LYs0VVw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# review the data\n",
        "for i in split_dataset.take(2):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMv6N5Oo1VEg",
        "outputId": "d9f7294a-8285-4b65-b518-d9f5334680f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# review the data\n",
        "for i in init_dataset.take(2):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "qwV0KKtS0f3K",
        "outputId": "e27b85ce-64b7-40f1-ad09-dce27038f1fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va ! endtoken'], dtype=object)>)\n",
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche. endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Notice how nicely english and french text have been separated now"
      ],
      "metadata": {
        "id": "POImeH-61gM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets attach this Vectorizer to init_dataset to get the vocabulary list\n",
        "english_training_dataset = init_dataset.map(lambda x,y:x) ##input is x, y and output is x\n",
        "english_vectorize_layer.adapt(english_training_dataset) ##adapt the vectorizer layer to training data"
      ],
      "metadata": {
        "id": "Hpm8-oPOyizU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets attach this Vectorizer to init_dataset to get the vocabulary list\n",
        "french_training_data=init_dataset.map(lambda x,y:y) ##input x,y,z and output y\n",
        "french_vectorize_layer.adapt(french_training_data) ##adapt the vectorize_layer to the training data"
      ],
      "metadata": {
        "id": "EhjbC0FC15im"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(english_vectorize_layer.get_vocabulary()))\n",
        "print(len(french_vectorize_layer.get_vocabulary()))"
      ],
      "metadata": {
        "id": "59TkjHwv12Px",
        "outputId": "8ba711ad-cef6-46e3-e041-9e98beaa675d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16952\n",
            "20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now data is adapted do vectorization (convert to numbers)"
      ],
      "metadata": {
        "id": "XYq1IZsl7ysT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(inputs,output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
      ],
      "metadata": {
        "id": "HA6Msvqu15gN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "id": "M2f-8iua15dO",
        "outputId": "846e3813-5311-4292-827c-50b3c735fda7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- get the final vectorized dataset"
      ],
      "metadata": {
        "id": "DifLzhDd8D66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = split_dataset.map(vectorize)"
      ],
      "metadata": {
        "id": "yBeRD80015aO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the data \"Go means Va in french\"\n",
        "english_vectorize_layer.get_vocabulary()[45]"
      ],
      "metadata": {
        "id": "YmgFBCug7rKC",
        "outputId": "40a735ab-4970-4747-98e7-4870dadc0df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.str_('go')"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the data\n",
        "french_vectorize_layer.get_vocabulary()[104]"
      ],
      "metadata": {
        "id": "5x4s9nYiDfEE",
        "outputId": "93d076b0-6863-4d88-e326-c72892721f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.str_('va')"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(2):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "ly-9riLs7rPS",
        "outputId": "e47864fd-0adb-4965-eb79-50d1841dd13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[104,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n",
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 811,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[811,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-"
      ],
      "metadata": {
        "id": "obxP29lqDGy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "2RTD9J6-7rM-",
        "outputId": "9c48a79a-18a5-41f8-e90c-c8eb0d398b2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create pipeline : by shuffling data and batch the data now"
      ],
      "metadata": {
        "id": "PXK3HAZTENEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64"
      ],
      "metadata": {
        "id": "M_8JULEYKbt_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "TBTp2iNHDZuH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "i9K5-MkuH6wQ",
        "outputId": "5decffea-ee80-49ff-e0f4-d19833a9d2c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confirm batching shape : batch\n",
        "for x, y in dataset.take(1):\n",
        "    print(x['input_1'].shape)  # Shape: (batch_size, seq_len)\n",
        "    print(x['input_2'].shape)\n",
        "    print(y.shape)"
      ],
      "metadata": {
        "id": "QjnDcCeXG7Le",
        "outputId": "3256567c-8079-4dfb-857d-3f56b7d830e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64)\n",
            "(64, 64)\n",
            "(64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for number of batches\n",
        "NUM_BATCHES= int(200000/BATCH_SIZE) ## since i have 200,000 data point in dataset and batch =64\n",
        "print(NUM_BATCHES)"
      ],
      "metadata": {
        "id": "1JKrq7D77rBO",
        "outputId": "c1d38520-ba40-4830-be87-2ac69908f259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.take(int(0.9*NUM_BATCHES))  ## i will use 90% of data for training\n",
        "val_dataset = dataset.skip(int(0.9*NUM_BATCHES))   ## rest 10% i will just push in validation"
      ],
      "metadata": {
        "id": "SOgd7WTI7q-H"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "Nw8MgaQkFtxZ",
        "outputId": "3124149c-c924-45cb-8cad-58cc281779d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "id": "GwdOW2TnFtoD",
        "outputId": "eb609a46-15fd-4d77-b841-f9484f7ba1bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_SkipDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "PWdDgTAeGTM1",
        "outputId": "e5c0bf22-5077-4495-cd47-7dfe69ba7813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "tM0uHoQh0nh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "uhkiRjk6DaKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#build postional encoding layer\n",
        "def positional_encoding(model_size,SEQUENCE_LENGTH):\n",
        "  output=[]\n",
        "  for pos in range(SEQUENCE_LENGTH):\n",
        "    PE=np.zeros((model_size))\n",
        "    for i in range(model_size):\n",
        "      if i%2==0:\n",
        "        PE[i]=np.sin(pos/(10000**(i/model_size)))\n",
        "      else:\n",
        "        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n",
        "    output.append(tf.expand_dims(PE,axis=0))\n",
        "  out=tf.concat(output,axis=0)\n",
        "  out=tf.expand_dims(out,axis=0)\n",
        "  return tf.cast(out,dtype=tf.float32)"
      ],
      "metadata": {
        "id": "XHUIm2qwDiie"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(positional_encoding(256,64).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUpBhkZcDifi",
        "outputId": "f9dffc3e-5fdd-4c6e-8d2d-a131c6958fc5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embed_dim,):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(\n",
        "        input_dim=vocab_size, output_dim = embed_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "    self.supports_masking = True\n",
        "\n",
        "  def call(self,inputs):\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions = positional_encoding(\n",
        "        self.embed_dim, self.sequence_length)\n",
        "    return embedded_tokens +embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    return tf.math.not_equal(inputs,0)"
      ],
      "metadata": {
        "id": "gqXixu3JDicw"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embed_dim,):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(\n",
        "        input_dim=vocab_size, output_dim = embed_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "    self.supports_masking = True\n",
        "\n",
        "  def call(self,inputs):\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions = positional_encoding(\n",
        "        self.embed_dim, self.sequence_length)\n",
        "    return embedded_tokens +embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    # Wrap tf.math.not_equal in a Lambda layer to handle KerasTensors\n",
        "    return tf.keras.layers.Lambda(lambda x: tf.math.not_equal(x, 0))(inputs)"
      ],
      "metadata": {
        "id": "Z_0slEXUEhZb"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input=tf.constant([[2,4,7,21,3,5,0,0]])\n",
        "emb=Embeddings(8,20000,512)\n",
        "emb_out=emb(test_input)\n",
        "print(emb_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9A7WINdY32K",
        "outputId": "63557a35-9915-4fb9-ee16-f4e2083d1b52"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain mask\n",
        "mask = emb.compute_mask(test_input)\n",
        "print(mask)  # check for 2 false at the end they are paddings\n",
        "\n",
        "#obtain padding mask\n",
        "padding_mask = tf.cast(\n",
        "    tf.repeat(mask,repeats=tf.shape(mask)[1],axis=0),\n",
        "    dtype=tf.int32)\n",
        "print(padding_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMMjDKhrbr4r",
        "outputId": "a5c8d0c4-ad9c-4fa4-b612-57747ac3ffb8"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ True  True  True  True  True  True False False]], shape=(1, 8), dtype=bool)\n",
            "tf.Tensor(\n",
            "[[1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0]\n",
            " [1 1 1 1 1 1 0 0]], shape=(8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.linalg.band_part(\n",
        "    tf.ones([1,8,8], dtype=tf.int32),-1,0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzz-Lr2abruW",
        "outputId": "11fb9457-5e95-427f-e2a3-a518e0505f56"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 1 0]\n",
            "  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #obtain mask\n",
        "# mask = emb.compute_mask(test_input)\n",
        "# print(mask)  # check for 2 false at the end they are paddings\n",
        "# mask = tf.cast(mask, dtype=tf.int32)\n",
        "# print(mask)\n",
        "# mask = mask[:,tf.newaxis,:]\n",
        "# print(tf.repeat(mask,8,axis=1))\n"
      ],
      "metadata": {
        "id": "rGli3Fy-nrwS"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = emb.compute_mask(test_input)\n",
        "mask1 = mask[:,:,tf.newaxis]\n",
        "mask2 = mask[:,tf.newaxis,:]\n",
        "padding_mask = tf.cast(mask1&mask2,dtype=\"int32\")\n",
        "print(padding_mask)"
      ],
      "metadata": {
        "id": "GDgIDW76xbai",
        "outputId": "1125268a-e74d-4e04-b9c4-ada861c56006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder : LSTM"
      ],
      "metadata": {
        "id": "hCqg5sGdm-zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):  # Inherits from the tf.keras.Model base class\n",
        "    def __init__(self, vocab_size, embedding_dims, units):\n",
        "        super(Encoder, self).__init__()  #Call the base class constructor\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.units = units\n",
        "\n",
        "    #Define the layers in the constructor\n",
        "    def build(self,input_shape):\n",
        "        self.embedding = Embedding(self.vocab_size, self.embedding_dims)\n",
        "        self.lstm = LSTM(self.units, return_sequences=True)\n",
        "\n",
        "    def call(self, x):  # This is the forward pass used during model execution\n",
        "        x = self.embedding(x)  # Convert input tokens to dense vector embeddings\n",
        "        output = self.lstm(x)  # Pass embeddings through LSTM\n",
        "        return output          # Return the output of the LSTM (sequence of hidden states)\n",
        "\n"
      ],
      "metadata": {
        "id": "VUVUMCjrnASG"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_UNITS = 256 # this are hidden state units for encoder\n",
        "EMBEDDING_DIM = 256\n",
        "encoder= Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS)\n",
        "#perform a dry run to check\n",
        "encoder_output=encoder(tf.zeros([128,8]))\n",
        "print(encoder_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOChTXYXnAPd",
        "outputId": "08f8928f-896c-474e-f217-1ffd9bb87698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 8, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bahdanau Attention : attention layer"
      ],
      "metadata": {
        "id": "uBBVfNMInEif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self,units):\n",
        "    super(BahdanauAttention,self).__init__()  #Call the base class constructor\n",
        "    self.units = units\n",
        "\n",
        "  #define layers in model\n",
        "  def build(self,input_shape):\n",
        "    self.w_1=tf.keras.layers.Dense(self.units)\n",
        "    self.w_2=tf.keras.layers.Dense(self.units)\n",
        "    self.w  =tf.keras.layers.Dense(1)  #tanh activation\n",
        "\n",
        "  #This is the forward pass used during model execution\n",
        "  def call(self,prev_dec_state, enc_states):\n",
        "    scores=self.w(\n",
        "        tf.nn.tanh(\n",
        "            self.w_1(tf.expand_dims(prev_dec_state,-2)) +  ## we are passing these from self.w cause it should be reduced to 1 dimension\n",
        "            self.w_2(enc_states)))\n",
        "\n",
        "\n",
        "    attention_weights=tf.nn.softmax(scores,axis=1)\n",
        "    context_vector=attention_weights*enc_states\n",
        "    context_vector=tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "uIxN3hE8nFxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau_attention=BahdanauAttention(256)\n",
        "context_vector,attention_weights=bahdanau_attention(tf.zeros([128,32]),tf.zeros([128,8,32]))\n",
        "print(context_vector.shape)\n",
        "print(attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RyZA6ElnFuZ",
        "outputId": "f568d88d-1fc3-439d-92dd-0d10fd527b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 32)\n",
            "(128, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "m6_htT-_nJwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, sequence_length):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.dec_units = dec_units\n",
        "    self.sequence_length = sequence_length\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.dense = Dense(self.vocab_size, activation=\"softmax\")\n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True)\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "\n",
        "  def call(self, x, hidden, shifted_target):\n",
        "    outputs = []\n",
        "    context_vectors = []\n",
        "    attention_weightss = []\n",
        "\n",
        "    shifted_target = self.embedding(shifted_target)  # shape: (128, 64, embedding_dim)\n",
        "\n",
        "    for t in range(0, self.sequence_length):\n",
        "      context_vector, attention_weights = self.attention(hidden, x)  # (128, dec_units), (128, 8, 1)\n",
        "      dec_input = context_vector + shifted_target[:, t, :]  # shape: (128, embedding_dim)\n",
        "      output, hidden = self.gru(tf.expand_dims(dec_input, 1))  # output: (128, 1, dec_units)\n",
        "      outputs.append(output[:, 0])  # (128, dec_units)\n",
        "      attention_weightss.append(attention_weights)  # each is (128, 8, 1)\n",
        "\n",
        "    outputs = tf.stack(outputs, axis=1)  # (128, 64, dec_units)\n",
        "    outputs = self.dense(outputs)        # (128, 64, vocab_size)\n",
        "\n",
        "    attention_weightss = tf.stack(attention_weightss, axis=1)  # (128, 64, 8, 1)\n",
        "    attention_weights = attention_weightss[:, -1, :, :]        # just final timestep: (128, 8, 1)\n",
        "\n",
        "    return outputs, attention_weights\n"
      ],
      "metadata": {
        "id": "tP1aVKzqnLcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,FRENCH_SEQUENCE_LENGTH)\n",
        "outputs,attention_weights=decoder(encoder_output,tf.zeros([128,HIDDEN_UNITS]),tf.zeros([128,64]))\n",
        "print(outputs.shape)\n",
        "print(attention_weights.shape)"
      ],
      "metadata": {
        "id": "MI2I7-U4hBq1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ENCODER\n",
        "input = Input(shape=(ENGLISH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_1\")\n",
        "encoder=Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS)\n",
        "encoder_output=encoder(input)\n",
        "\n",
        "### DECODER\n",
        "shifted_target=Input(shape=(FRENCH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_2\")\n",
        "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,FRENCH_SEQUENCE_LENGTH)\n",
        "decoder_output,attention_weightss=decoder(encoder_output,tf.zeros([1,HIDDEN_UNITS]),shifted_target)\n",
        "\n",
        "### OUTPUT\n",
        "bahdanau=Model([input,shifted_target],decoder_output)\n",
        "bahdanau.summary()"
      ],
      "metadata": {
        "id": "w4zKaaQMGktR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom MultiHeadAttention"
      ],
      "metadata": {
        "id": "TP8tktdcrRey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSelfAttention(Layer):\n",
        "  def __init__(self,model_size):\n",
        "    super(CustomSelfAttention,self).__init__()\n",
        "    self.model_size=model_size\n",
        "  def call(self,query,key,value,masking):\n",
        "    ######## compute scores\n",
        "    score=tf.matmul(query,key,transpose_b=True)\n",
        "    ######## scaling\n",
        "    score/=tf.math.sqrt(tf.cast(self.model_size,tf.float32))\n",
        "    print('score--->', score)\n",
        "    ######## masking\n",
        "    masking=tf.cast(masking,dtype=tf.float32)\n",
        "    print('mask--->', masking)\n",
        "    score+=(1.-masking)*-1e10\n",
        "    print('scoringaftermasking--->', score)\n",
        "    ######## attention_weights\n",
        "    attention=tf.nn.softmax(score,axis=-1)*masking\n",
        "    print(attention)\n",
        "    ######## output\n",
        "    head=tf.matmul(attention,value)\n",
        "    return head"
      ],
      "metadata": {
        "id": "Ua9GwpcYrTZc"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention=CustomSelfAttention(256)\n",
        "attention(tf.ones([1,8,256]),tf.ones([1,8,256]),tf.ones([1,8,256]),padding_mask)"
      ],
      "metadata": {
        "id": "3dR0aLKprTLH",
        "outputId": "06e4c82e-188f-4d33-e62e-f38cf003eab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score---> tf.Tensor(\n",
            "[[[16. 16. 16. 16. 16. 16. 16. 16.]\n",
            "  [16. 16. 16. 16. 16. 16. 16. 16.]\n",
            "  [16. 16. 16. 16. 16. 16. 16. 16.]\n",
            "  [16. 16. 16. 16. 16. 16. 16. 16.]\n",
            "  [16. 16. 16. 16. 16. 16. 16. 16.]\n",
            "  [16. 16. 16. 16. 16. 16. 16. 16.]\n",
            "  [16. 16. 16. 16. 16. 16. 16. 16.]\n",
            "  [16. 16. 16. 16. 16. 16. 16. 16.]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[ 1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01 -1.0e+10\n",
            "   -1.0e+10]\n",
            "  [ 1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01 -1.0e+10\n",
            "   -1.0e+10]\n",
            "  [ 1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01 -1.0e+10\n",
            "   -1.0e+10]\n",
            "  [ 1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01 -1.0e+10\n",
            "   -1.0e+10]\n",
            "  [ 1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01 -1.0e+10\n",
            "   -1.0e+10]\n",
            "  [ 1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01  1.6e+01 -1.0e+10\n",
            "   -1.0e+10]\n",
            "  [-1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10\n",
            "   -1.0e+10]\n",
            "  [-1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10 -1.0e+10\n",
            "   -1.0e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667\n",
            "   0.         0.        ]\n",
            "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667\n",
            "   0.         0.        ]\n",
            "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667\n",
            "   0.         0.        ]\n",
            "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667\n",
            "   0.         0.        ]\n",
            "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667\n",
            "   0.         0.        ]\n",
            "  [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667\n",
            "   0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8, 256), dtype=float32, numpy=\n",
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMultiHeadAttention(Layer):\n",
        "  def __init__(self,num_heads,key_dim):\n",
        "    super(CustomMultiHeadAttention,self).__init__()\n",
        "\n",
        "    self.num_heads=num_heads\n",
        "    self.dense_q=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
        "    self.dense_k=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
        "    self.dense_v=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n",
        "    self.dense_o=Dense(key_dim) #output\n",
        "    self.self_attention=CustomSelfAttention(key_dim)\n",
        "\n",
        "  def call(self,query,key,value,attention_mask):\n",
        "    heads=[]\n",
        "\n",
        "    for i in range(self.num_heads):\n",
        "      print(\"hello\", self.dense_q[i](query).shape)\n",
        "      head=self.self_attention(self.dense_q[i](query),\n",
        "                               self.dense_k[i](key),\n",
        "                               self.dense_v[i](value),\n",
        "                               attention_mask)\n",
        "      heads.append(head)\n",
        "    print(\"head\", tf.convert_to_tensor(heads).shape)\n",
        "    heads=tf.concat(heads,axis=2)\n",
        "    heads=self.dense_o(heads)\n",
        "    return heads"
      ],
      "metadata": {
        "id": "qJSD3YF23P5B"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Transformer Model"
      ],
      "metadata": {
        "id": "hFWDS4XufR4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads,):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = CustomMultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim,\n",
        "        )\n",
        "        self.dense_proj=tf.keras.Sequential(\n",
        "            [Dense(dense_dim, activation=\"relu\"),\n",
        "             Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n",
        "        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "\n",
        "      if mask is not None:\n",
        "        mask = tf.cast(\n",
        "            mask[:,tf.newaxis, :], dtype=\"int32\")\n",
        "        T = tf.shape(mask)[2]\n",
        "        padding_mask = tf.repeat(mask,T,axis=1)\n",
        "      attention_output = self.attention(\n",
        "          query=inputs, key=inputs,value=inputs,\n",
        "          attention_mask=padding_mask\n",
        "      )\n",
        "\n",
        "      proj_input = self.layernorm_1(inputs + attention_output)\n",
        "      proj_output = self.dense_proj(proj_input)\n",
        "      return self.layernorm_2(proj_input + proj_output)"
      ],
      "metadata": {
        "id": "gOk7MVEgfXbR"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs = TransformerEncoder(512, 2048, 8)(emb_out, mask=mask)\n",
        "print(encoder_outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOlAsuY9fXYR",
        "outputId": "bb00ecee-06d9-4a86-ac0e-ae779b064961"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_self_attention_30_1/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_1/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_1/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_1/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_self_attention_30_3/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_3/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_3/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_3/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_self_attention_30_5/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_5/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_5/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_5/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_self_attention_30_7/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_7/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_7/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_7/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_self_attention_30_9/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_9/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_9/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_9/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'custom_self_attention_30' (of type CustomSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score---> Tensor(\"custom_self_attention_30_11/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_11/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_11/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_11/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_self_attention_30_13/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_13/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_13/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_13/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_self_attention_30_15/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_30_15/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_30_15/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_self_attention_30_15/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "head (8, 1, 8, 64)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_1/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_1/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_1/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_1/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_3/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_3/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_3/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_3/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_5/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_5/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_5/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_5/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_7/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_7/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_7/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_7/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_9/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_9/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_9/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_9/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_11/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_11/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_11/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_11/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_13/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_13/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_13/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_13/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_15/truediv:0\", shape=(1, 8, 8), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_15/Cast_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_15/add:0\", shape=(1, 8, 8), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_16_1/custom_self_attention_30_15/mul_1:0\", shape=(1, 8, 8), dtype=float32)\n",
            "head (8, 1, 8, 64)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[ 0.02956816 -0.04493785 -0.01090334  0.08704668  0.18171416\n",
            "    0.22068594  0.1688246   0.08134244]\n",
            "  [ 0.05704978 -0.00684322  0.03964815  0.14771298  0.24714449\n",
            "    0.27942893  0.20609963  0.0920645 ]\n",
            "  [ 0.13335113  0.09062707  0.14613041  0.2529779   0.3438001\n",
            "    0.3604018   0.26548362  0.13086998]\n",
            "  [ 0.23155992  0.18971676  0.24020724  0.34035805  0.41892198\n",
            "    0.42722204  0.31284449  0.16896865]\n",
            "  [ 0.21894924  0.16464052  0.20193024  0.29993927  0.37814364\n",
            "    0.38827002  0.26428396  0.11679965]\n",
            "  [ 0.11524507  0.03953211  0.06606603  0.16378698  0.2472413\n",
            "    0.2654871   0.14078656 -0.00173101]\n",
            "  [-0.06244864 -0.15043539 -0.13604504 -0.03081447  0.07111018\n",
            "    0.11297283  0.00591931 -0.12554982]\n",
            "  [-0.14370435 -0.22660805 -0.20753035 -0.08796001  0.0355581\n",
            "    0.09990475  0.00981788 -0.11410684]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[ 2.95681581e-02 -4.49378453e-02 -1.09033426e-02  8.70466828e-02\n",
            "    1.81714162e-01  2.20685944e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 5.70497848e-02 -6.84321532e-03  3.96481454e-02  1.47712976e-01\n",
            "    2.47144490e-01  2.79428929e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 1.33351132e-01  9.06270668e-02  1.46130413e-01  2.52977908e-01\n",
            "    3.43800098e-01  3.60401809e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 2.31559917e-01  1.89716756e-01  2.40207240e-01  3.40358049e-01\n",
            "    4.18921977e-01  4.27222043e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 2.18949243e-01  1.64640516e-01  2.01930240e-01  2.99939275e-01\n",
            "    3.78143638e-01  3.88270020e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 1.15245067e-01  3.95321064e-02  6.60660267e-02  1.63786978e-01\n",
            "    2.47241303e-01  2.65487105e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-6.24486394e-02 -1.50435388e-01 -1.36045039e-01 -3.08144670e-02\n",
            "    7.11101815e-02  1.12972826e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.43704355e-01 -2.26608053e-01 -2.07530349e-01 -8.79600123e-02\n",
            "    3.55580971e-02  9.99047458e-02 -1.00000000e+10 -1.00000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.15816194 0.14680623 0.1518887  0.16751921 0.18415274 0.19147117\n",
            "   0.         0.        ]\n",
            "  [0.15446012 0.14489985 0.1517955  0.1691184  0.18679851 0.1929276\n",
            "   0.         0.        ]\n",
            "  [0.15180868 0.1454594  0.15376113 0.17109995 0.18736713 0.19050372\n",
            "   0.         0.        ]\n",
            "  [0.15373212 0.1474322  0.15506725 0.17140165 0.18541075 0.18695606\n",
            "   0.         0.        ]\n",
            "  [0.15694422 0.14864808 0.15429579 0.17018403 0.18402743 0.18590042\n",
            "   0.         0.        ]\n",
            "  [0.1604608  0.14876038 0.15276039 0.16844203 0.18310246 0.18647398\n",
            "   0.         0.        ]\n",
            "  [0.16098921 0.14742957 0.14956647 0.16616338 0.18399273 0.19185863\n",
            "   0.         0.        ]\n",
            "  [0.15654068 0.14408627 0.14686151 0.16551474 0.18727505 0.19972172\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[ 0.11822648  0.212998    0.26198667  0.27131382  0.20730865\n",
            "    0.17976461  0.08397344  0.09214454]\n",
            "  [ 0.04096657  0.12210011  0.16846962  0.19357279  0.15809095\n",
            "    0.14545429  0.03222415  0.00785118]\n",
            "  [-0.00098136  0.05910994  0.07894288  0.10809046  0.09822837\n",
            "    0.11198331  0.0004711  -0.04652544]\n",
            "  [-0.08744226 -0.05283982 -0.05918615 -0.03038327 -0.03305596\n",
            "   -0.00815185 -0.13000786 -0.20436735]\n",
            "  [-0.13400617 -0.12885876 -0.1539187  -0.12346688 -0.11783952\n",
            "   -0.07840102 -0.1979685  -0.29514894]\n",
            "  [-0.1650313  -0.17821087 -0.21426453 -0.19160599 -0.18901251\n",
            "   -0.14450748 -0.24963556 -0.3426709 ]\n",
            "  [-0.18528874 -0.21139655 -0.2484043  -0.22048593 -0.20620477\n",
            "   -0.14269075 -0.2230798  -0.30845615]\n",
            "  [-0.20525695 -0.24183103 -0.28852472 -0.2582883  -0.23159926\n",
            "   -0.14924887 -0.20212223 -0.26588956]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[ 1.18226476e-01  2.12998003e-01  2.61986673e-01  2.71313816e-01\n",
            "    2.07308650e-01  1.79764614e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 4.09665741e-02  1.22100115e-01  1.68469623e-01  1.93572789e-01\n",
            "    1.58090949e-01  1.45454288e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-9.81363002e-04  5.91099449e-02  7.89428800e-02  1.08090460e-01\n",
            "    9.82283652e-02  1.11983314e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-8.74422565e-02 -5.28398193e-02 -5.91861531e-02 -3.03832740e-02\n",
            "   -3.30559574e-02 -8.15185346e-03 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.34006172e-01 -1.28858760e-01 -1.53918698e-01 -1.23466879e-01\n",
            "   -1.17839515e-01 -7.84010217e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.65031299e-01 -1.78210869e-01 -2.14264527e-01 -1.91605985e-01\n",
            "   -1.89012513e-01 -1.44507483e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.85288742e-01 -2.11396545e-01 -2.48404294e-01 -2.20485926e-01\n",
            "   -2.06204772e-01 -1.42690748e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-2.05256954e-01 -2.41831034e-01 -2.88524717e-01 -2.58288294e-01\n",
            "   -2.31599256e-01 -1.49248868e-01 -1.00000000e+10 -1.00000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.15206622 0.16718274 0.17557673 0.17722203 0.16623428 0.16171801\n",
            "   0.         0.        ]\n",
            "  [0.15106264 0.16382979 0.1716054  0.17596775 0.16983357 0.16770095\n",
            "   0.         0.        ]\n",
            "  [0.15421933 0.16377068 0.16705115 0.17199194 0.17030409 0.17266278\n",
            "   0.         0.        ]\n",
            "  [0.15971898 0.16534238 0.16429637 0.16909741 0.16864605 0.17289877\n",
            "   0.         0.        ]\n",
            "  [0.16475773 0.16560799 0.16150942 0.16650335 0.16744296 0.1741786\n",
            "   0.         0.        ]\n",
            "  [0.16921386 0.16699834 0.16108468 0.1647763  0.16520418 0.17272267\n",
            "   0.         0.        ]\n",
            "  [0.1694542  0.16508737 0.15908954 0.16359365 0.1659467  0.17682856\n",
            "   0.         0.        ]\n",
            "  [0.17052771 0.1644035  0.15690336 0.16172    0.16609426 0.18035117\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[-9.7758710e-02 -1.4643893e-01 -1.9534504e-01 -2.1922109e-01\n",
            "   -1.8055470e-01 -1.6279487e-01 -1.2886332e-01 -1.0431656e-01]\n",
            "  [-1.8058966e-01 -2.3593727e-01 -2.8548196e-01 -2.9482797e-01\n",
            "   -2.3011358e-01 -1.7993401e-01 -1.2344694e-01 -1.0388699e-01]\n",
            "  [-2.6065364e-01 -3.0119038e-01 -3.2428065e-01 -3.0516079e-01\n",
            "   -2.2568779e-01 -1.5886678e-01 -9.3529001e-02 -7.9226926e-02]\n",
            "  [-1.8367305e-01 -1.9652186e-01 -1.9199030e-01 -1.4687923e-01\n",
            "   -6.8021767e-02  3.6194135e-04  6.2827483e-02  6.8953246e-02]\n",
            "  [-8.1124634e-02 -6.6888914e-02 -4.9960811e-02  6.5493984e-03\n",
            "    7.2970718e-02  1.3967903e-01  2.0350771e-01  2.1357745e-01]\n",
            "  [ 2.7699515e-02  6.2303938e-02  8.3923653e-02  1.4411429e-01\n",
            "    2.0487119e-01  2.7515861e-01  3.3924606e-01  3.5411122e-01]\n",
            "  [ 5.0725993e-02  9.5758483e-02  1.1328494e-01  1.7619252e-01\n",
            "    2.3482971e-01  3.0928543e-01  3.6762241e-01  3.7994820e-01]\n",
            "  [ 5.2481063e-02  1.0009622e-01  1.1219262e-01  1.7471007e-01\n",
            "    2.3004958e-01  3.0682847e-01  3.7180847e-01  3.9160547e-01]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[-9.7758710e-02 -1.4643893e-01 -1.9534504e-01 -2.1922109e-01\n",
            "   -1.8055470e-01 -1.6279487e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.8058966e-01 -2.3593727e-01 -2.8548196e-01 -2.9482797e-01\n",
            "   -2.3011358e-01 -1.7993401e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-2.6065364e-01 -3.0119038e-01 -3.2428065e-01 -3.0516079e-01\n",
            "   -2.2568779e-01 -1.5886678e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.8367305e-01 -1.9652186e-01 -1.9199030e-01 -1.4687923e-01\n",
            "   -6.8021767e-02  3.6194135e-04 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-8.1124634e-02 -6.6888914e-02 -4.9960811e-02  6.5493984e-03\n",
            "    7.2970718e-02  1.3967903e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 2.7699515e-02  6.2303938e-02  8.3923653e-02  1.4411429e-01\n",
            "    2.0487119e-01  2.7515861e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 5.0725993e-02  9.5758483e-02  1.1328494e-01  1.7619252e-01\n",
            "    2.3482971e-01  3.0928543e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 5.2481063e-02  1.0009622e-01  1.1219262e-01  1.7471007e-01\n",
            "    2.3004958e-01  3.0682847e-01 -1.0000000e+10 -1.0000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.17848517 0.17000456 0.16189034 0.15807082 0.16430254 0.1672466\n",
            "   0.         0.        ]\n",
            "  [0.17571725 0.16625597 0.15821959 0.15674776 0.167227   0.1758325\n",
            "   0.         0.        ]\n",
            "  [0.16672698 0.16010357 0.15644908 0.15946916 0.17265984 0.18459135\n",
            "   0.         0.        ]\n",
            "  [0.15770154 0.15568823 0.15639533 0.16361205 0.17703642 0.18956637\n",
            "   0.         0.        ]\n",
            "  [0.15264136 0.15482986 0.15747313 0.16662823 0.17807172 0.19035575\n",
            "   0.         0.        ]\n",
            "  [0.14945205 0.15471427 0.15809555 0.16790366 0.17842123 0.19141324\n",
            "   0.         0.        ]\n",
            "  [0.14833495 0.15516752 0.15791103 0.16816394 0.17831942 0.1921031\n",
            "   0.         0.        ]\n",
            "  [0.1487157  0.15596811 0.15786622 0.16805066 0.17761263 0.1917867\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[-0.38689387 -0.42606515 -0.37809175 -0.26204008 -0.19944176\n",
            "   -0.08511996  0.01464929  0.11897714]\n",
            "  [-0.41311634 -0.43143025 -0.3696762  -0.2575024  -0.19995858\n",
            "   -0.0984033  -0.00756445  0.08432786]\n",
            "  [-0.366719   -0.3653706  -0.30135232 -0.20599267 -0.16479889\n",
            "   -0.08505274 -0.00185997  0.07864897]\n",
            "  [-0.2964756  -0.27717963 -0.20495228 -0.11926631 -0.08371802\n",
            "   -0.02257144  0.04566053  0.10418157]\n",
            "  [-0.24095935 -0.21075578 -0.1271863  -0.04682714 -0.01802552\n",
            "    0.0247717   0.07619221  0.1226891 ]\n",
            "  [-0.17965883 -0.15099905 -0.07090261 -0.0075197   0.01624366\n",
            "    0.05530447  0.10644168  0.15720026]\n",
            "  [-0.14079103 -0.13055742 -0.06054374  0.00271615  0.03209073\n",
            "    0.08711332  0.14448568  0.20745036]\n",
            "  [-0.11809609 -0.13515349 -0.08058456 -0.00963684  0.03296137\n",
            "    0.11460897  0.1787591   0.25547603]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[-3.86893868e-01 -4.26065147e-01 -3.78091753e-01 -2.62040079e-01\n",
            "   -1.99441761e-01 -8.51199627e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-4.13116336e-01 -4.31430250e-01 -3.69676203e-01 -2.57502407e-01\n",
            "   -1.99958578e-01 -9.84032974e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-3.66719007e-01 -3.65370601e-01 -3.01352322e-01 -2.05992669e-01\n",
            "   -1.64798886e-01 -8.50527436e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-2.96475589e-01 -2.77179629e-01 -2.04952285e-01 -1.19266309e-01\n",
            "   -8.37180167e-02 -2.25714445e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-2.40959346e-01 -2.10755780e-01 -1.27186298e-01 -4.68271449e-02\n",
            "   -1.80255175e-02  2.47716997e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.79658830e-01 -1.50999054e-01 -7.09026083e-02 -7.51970382e-03\n",
            "    1.62436590e-02  5.53044677e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.40791029e-01 -1.30557418e-01 -6.05437383e-02  2.71615363e-03\n",
            "    3.20907310e-02  8.71133208e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.18096091e-01 -1.35153487e-01 -8.05845633e-02 -9.63684358e-03\n",
            "    3.29613686e-02  1.14608966e-01 -1.00000000e+10 -1.00000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.15010874 0.14434245 0.15143584 0.1700706  0.181057   0.20298535\n",
            "   0.         0.        ]\n",
            "  [0.14701404 0.14434615 0.15354109 0.17176753 0.18194161 0.20138955\n",
            "   0.         0.        ]\n",
            "  [0.14722444 0.1474231  0.15716952 0.17289503 0.18016596 0.19512191\n",
            "   0.         0.        ]\n",
            "  [0.14574327 0.14858283 0.15971164 0.1740001  0.18029678 0.19166532\n",
            "   0.         0.        ]\n",
            "  [0.14451826 0.1489498  0.1619324  0.17548229 0.18060994 0.18850733\n",
            "   0.         0.        ]\n",
            "  [0.14677653 0.15104397 0.16363975 0.17434748 0.17854019 0.18565209\n",
            "   0.         0.        ]\n",
            "  [0.14941323 0.15095012 0.16189745 0.17246994 0.17761134 0.18765782\n",
            "   0.         0.        ]\n",
            "  [0.15241711 0.14983933 0.1582431  0.16987793 0.17727077 0.1923518\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[-0.11703733 -0.12504789 -0.07709739 -0.05273924 -0.11081806\n",
            "   -0.29060894 -0.5272231  -0.69446135]\n",
            "  [-0.16818249 -0.21111138 -0.18167616 -0.14735413 -0.18231006\n",
            "   -0.3276618  -0.54706544 -0.7115807 ]\n",
            "  [-0.18024956 -0.26221713 -0.25428876 -0.20696272 -0.20211816\n",
            "   -0.29494706 -0.4858585  -0.65238714]\n",
            "  [-0.18081146 -0.27812642 -0.27691963 -0.23025355 -0.20069836\n",
            "   -0.2698348  -0.44795272 -0.6233651 ]\n",
            "  [-0.13139215 -0.22864439 -0.22521797 -0.18144202 -0.1344735\n",
            "   -0.184415   -0.35182217 -0.5419174 ]\n",
            "  [-0.05092955 -0.12276744 -0.10865994 -0.08525325 -0.05316916\n",
            "   -0.10081827 -0.25766551 -0.43883547]\n",
            "  [-0.01648694 -0.06852738 -0.05312904 -0.04971141 -0.02960994\n",
            "   -0.0693497  -0.20408413 -0.36693192]\n",
            "  [-0.03415575 -0.07831401 -0.0667263  -0.06914714 -0.05756467\n",
            "   -0.08914002 -0.20586345 -0.3494338 ]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[-1.1703733e-01 -1.2504789e-01 -7.7097386e-02 -5.2739237e-02\n",
            "   -1.1081806e-01 -2.9060894e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.6818249e-01 -2.1111138e-01 -1.8167616e-01 -1.4735413e-01\n",
            "   -1.8231006e-01 -3.2766181e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.8024956e-01 -2.6221713e-01 -2.5428876e-01 -2.0696272e-01\n",
            "   -2.0211816e-01 -2.9494706e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.8081146e-01 -2.7812642e-01 -2.7691963e-01 -2.3025355e-01\n",
            "   -2.0069836e-01 -2.6983479e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.3139215e-01 -2.2864439e-01 -2.2521797e-01 -1.8144202e-01\n",
            "   -1.3447350e-01 -1.8441500e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-5.0929546e-02 -1.2276744e-01 -1.0865994e-01 -8.5253246e-02\n",
            "   -5.3169157e-02 -1.0081827e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.6486935e-02 -6.8527378e-02 -5.3129043e-02 -4.9711406e-02\n",
            "   -2.9609943e-02 -6.9349699e-02 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-3.4155745e-02 -7.8314006e-02 -6.6726305e-02 -6.9147140e-02\n",
            "   -5.7564672e-02 -8.9140020e-02 -1.0000000e+10 -1.0000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.16817816 0.16683634 0.17503111 0.1793469  0.16922736 0.14138013\n",
            "   0.         0.        ]\n",
            "  [0.17228955 0.16504985 0.16998033 0.17591567 0.16987263 0.14689192\n",
            "   0.         0.        ]\n",
            "  [0.17563634 0.16181408 0.16310209 0.17100665 0.1718371  0.15660365\n",
            "   0.         0.        ]\n",
            "  [0.1765995  0.16022347 0.16041695 0.1680804  0.17312217 0.1615575\n",
            "   0.         0.        ]\n",
            "  [0.17500164 0.15878372 0.15932873 0.1664584  0.17446323 0.16596425\n",
            "   0.         0.        ]\n",
            "  [0.17271326 0.16074109 0.16302483 0.16688569 0.17232691 0.16430822\n",
            "   0.         0.        ]\n",
            "  [0.17193635 0.16321753 0.16575028 0.1663177  0.16969475 0.16308337\n",
            "   0.         0.        ]\n",
            "  [0.17200652 0.16457628 0.16649441 0.16609186 0.16802679 0.16280417\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[ 0.12638277  0.08547979 -0.00928854 -0.07775566 -0.09917221\n",
            "   -0.06381223  0.00158307  0.08372751]\n",
            "  [ 0.15495038  0.08629417 -0.0192236  -0.07878526 -0.0742891\n",
            "   -0.02167216  0.04123699  0.10292663]\n",
            "  [ 0.09961035  0.01175868 -0.08635091 -0.14125146 -0.11314504\n",
            "   -0.04079918  0.03720194  0.10575543]\n",
            "  [-0.02301801 -0.11215698 -0.18597883 -0.2323516  -0.18478507\n",
            "   -0.09454764  0.00818961  0.09970465]\n",
            "  [-0.09705013 -0.17115365 -0.2177263  -0.25824994 -0.21607372\n",
            "   -0.12565519 -0.00934261  0.10939201]\n",
            "  [-0.15268832 -0.20620118 -0.23677236 -0.26977074 -0.23860985\n",
            "   -0.15250863 -0.03448585  0.08983421]\n",
            "  [-0.09375747 -0.14721814 -0.17844321 -0.19329022 -0.16912813\n",
            "   -0.09132414  0.01018989  0.12077924]\n",
            "  [ 0.00769432 -0.05783891 -0.10775592 -0.11385699 -0.0900319\n",
            "   -0.0185171   0.05519506  0.13501638]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[ 1.26382768e-01  8.54797885e-02 -9.28854384e-03 -7.77556598e-02\n",
            "   -9.91722122e-02 -6.38122335e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 1.54950380e-01  8.62941667e-02 -1.92235950e-02 -7.87852630e-02\n",
            "   -7.42890984e-02 -2.16721594e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 9.96103510e-02  1.17586758e-02 -8.63509104e-02 -1.41251460e-01\n",
            "   -1.13145038e-01 -4.07991782e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-2.30180062e-02 -1.12156980e-01 -1.85978830e-01 -2.32351601e-01\n",
            "   -1.84785068e-01 -9.45476368e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-9.70501304e-02 -1.71153650e-01 -2.17726305e-01 -2.58249938e-01\n",
            "   -2.16073722e-01 -1.25655189e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-1.52688324e-01 -2.06201181e-01 -2.36772358e-01 -2.69770741e-01\n",
            "   -2.38609850e-01 -1.52508631e-01 -1.00000000e+10 -1.00000000e+10]\n",
            "  [-9.37574655e-02 -1.47218138e-01 -1.78443208e-01 -1.93290219e-01\n",
            "   -1.69128135e-01 -9.13241431e-02 -1.00000000e+10 -1.00000000e+10]\n",
            "  [ 7.69431842e-03 -5.78389131e-02 -1.07755922e-01 -1.13856986e-01\n",
            "   -9.00318995e-02 -1.85170993e-02 -1.00000000e+10 -1.00000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.18963556 0.1820354  0.16557643 0.15461925 0.15134306 0.15679029\n",
            "   0.         0.        ]\n",
            "  [0.19235934 0.17959584 0.16161084 0.15226609 0.15295225 0.16121562\n",
            "   0.         0.        ]\n",
            "  [0.19195667 0.17581248 0.15938275 0.1508684  0.15516892 0.16681078\n",
            "   0.         0.        ]\n",
            "  [0.186669   0.17074959 0.15859856 0.15141183 0.158788   0.173783\n",
            "   0.         0.        ]\n",
            "  [0.18097563 0.16804956 0.16040249 0.15403233 0.16066779 0.17587216\n",
            "   0.         0.        ]\n",
            "  [0.17622371 0.16704135 0.16201197 0.15675308 0.16171454 0.17625538\n",
            "   0.         0.        ]\n",
            "  [0.17538197 0.16625215 0.16114113 0.15876634 0.16264918 0.17580926\n",
            "   0.         0.        ]\n",
            "  [0.17875962 0.16742052 0.15926856 0.15829979 0.16211657 0.17413495\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[ 0.43717596  0.5562849   0.517967    0.4156851   0.32462853\n",
            "    0.29762974  0.28644884  0.31808397]\n",
            "  [ 0.16335009  0.31456396  0.31223768  0.2286754   0.12840764\n",
            "    0.07775407  0.04233084  0.06457967]\n",
            "  [ 0.01434653  0.19019364  0.20511165  0.13937408  0.0314122\n",
            "   -0.03641949 -0.09213992 -0.08251227]\n",
            "  [ 0.00995595  0.19041663  0.20361683  0.14424567  0.04171619\n",
            "   -0.01242127 -0.05760313 -0.04071398]\n",
            "  [ 0.14347969  0.3076154   0.30705458  0.2530544   0.17975157\n",
            "    0.16106716  0.14505035  0.16938663]\n",
            "  [ 0.36662427  0.49442074  0.46685842  0.40807474  0.35768133\n",
            "    0.37656882  0.38611966  0.4118403 ]\n",
            "  [ 0.49898157  0.59082294  0.5598322   0.5070448   0.48378557\n",
            "    0.52505964  0.5450429   0.5613959 ]\n",
            "  [ 0.51791054  0.59242     0.57310116  0.5232448   0.5024184\n",
            "    0.53031343  0.53458893  0.5354108 ]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[ 4.3717596e-01  5.5628490e-01  5.1796699e-01  4.1568509e-01\n",
            "    3.2462853e-01  2.9762974e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 1.6335009e-01  3.1456396e-01  3.1223768e-01  2.2867540e-01\n",
            "    1.2840764e-01  7.7754065e-02 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 1.4346534e-02  1.9019364e-01  2.0511165e-01  1.3937408e-01\n",
            "    3.1412195e-02 -3.6419492e-02 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 9.9559501e-03  1.9041663e-01  2.0361683e-01  1.4424567e-01\n",
            "    4.1716192e-02 -1.2421266e-02 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 1.4347969e-01  3.0761540e-01  3.0705458e-01  2.5305441e-01\n",
            "    1.7975157e-01  1.6106716e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 3.6662427e-01  4.9442074e-01  4.6685842e-01  4.0807474e-01\n",
            "    3.5768133e-01  3.7656882e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 4.9898157e-01  5.9082294e-01  5.5983222e-01  5.0704479e-01\n",
            "    4.8378557e-01  5.2505964e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [ 5.1791054e-01  5.9241998e-01  5.7310116e-01  5.2324480e-01\n",
            "    5.0241840e-01  5.3031343e-01 -1.0000000e+10 -1.0000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.16799147 0.18924116 0.18212701 0.16441971 0.15010962 0.14611106\n",
            "   0.         0.        ]\n",
            "  [0.15936458 0.18538012 0.18494938 0.17012268 0.15389216 0.1462911\n",
            "   0.         0.        ]\n",
            "  [0.15376753 0.18333021 0.18608564 0.17424622 0.15641418 0.14615619\n",
            "   0.         0.        ]\n",
            "  [0.15231553 0.18243882 0.18486303 0.17420696 0.15723075 0.14894499\n",
            "   0.         0.        ]\n",
            "  [0.15321979 0.18055025 0.18044902 0.17096317 0.15887938 0.15593837\n",
            "   0.         0.        ]\n",
            "  [0.15910482 0.18079427 0.1758792  0.16583839 0.1576883  0.16069494\n",
            "   0.         0.        ]\n",
            "  [0.16185507 0.17742406 0.17200989 0.16316542 0.15941411 0.16613145\n",
            "   0.         0.        ]\n",
            "  [0.16295792 0.17556362 0.17220448 0.1638295  0.16045281 0.16499166\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "hello (1, 8, 64)\n",
            "score---> tf.Tensor(\n",
            "[[[-0.02507637  0.04887621  0.13697317  0.12800112  0.09773127\n",
            "    0.03279958 -0.01376422 -0.01629368]\n",
            "  [-0.14103918 -0.04196566  0.05791707  0.06573167  0.03510128\n",
            "   -0.03240927 -0.08810741 -0.09504349]\n",
            "  [-0.30288556 -0.16592391 -0.04205468 -0.01035858 -0.04741089\n",
            "   -0.13214713 -0.22172569 -0.25579253]\n",
            "  [-0.444268   -0.268733   -0.11567011 -0.06384397 -0.10993986\n",
            "   -0.21016438 -0.3414234  -0.4066835 ]\n",
            "  [-0.48844254 -0.30519223 -0.141277   -0.08460785 -0.12646848\n",
            "   -0.23075649 -0.3755563  -0.45851132]\n",
            "  [-0.535237   -0.36579132 -0.21061394 -0.16468617 -0.20155124\n",
            "   -0.29912534 -0.43446204 -0.52006304]\n",
            "  [-0.49163163 -0.34881157 -0.21652438 -0.18891121 -0.20639113\n",
            "   -0.2933505  -0.39825663 -0.47878584]\n",
            "  [-0.49463913 -0.36566055 -0.24970883 -0.24173833 -0.24917053\n",
            "   -0.329727   -0.4057164  -0.474375  ]]], shape=(1, 8, 8), dtype=float32)\n",
            "mask---> tf.Tensor(\n",
            "[[[1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "  [1. 1. 1. 1. 1. 1. 0. 0.]]], shape=(1, 8, 8), dtype=float32)\n",
            "scoringaftermasking---> tf.Tensor(\n",
            "[[[-2.5076374e-02  4.8876211e-02  1.3697317e-01  1.2800112e-01\n",
            "    9.7731270e-02  3.2799579e-02 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-1.4103918e-01 -4.1965660e-02  5.7917073e-02  6.5731674e-02\n",
            "    3.5101280e-02 -3.2409269e-02 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-3.0288556e-01 -1.6592391e-01 -4.2054683e-02 -1.0358578e-02\n",
            "   -4.7410890e-02 -1.3214713e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-4.4426799e-01 -2.6873299e-01 -1.1567011e-01 -6.3843973e-02\n",
            "   -1.0993986e-01 -2.1016438e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-4.8844254e-01 -3.0519223e-01 -1.4127700e-01 -8.4607847e-02\n",
            "   -1.2646848e-01 -2.3075649e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-5.3523701e-01 -3.6579132e-01 -2.1061394e-01 -1.6468617e-01\n",
            "   -2.0155124e-01 -2.9912534e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-4.9163163e-01 -3.4881157e-01 -2.1652438e-01 -1.8891121e-01\n",
            "   -2.0639113e-01 -2.9335049e-01 -1.0000000e+10 -1.0000000e+10]\n",
            "  [-4.9463913e-01 -3.6566055e-01 -2.4970883e-01 -2.4173833e-01\n",
            "   -2.4917053e-01 -3.2972699e-01 -1.0000000e+10 -1.0000000e+10]]], shape=(1, 8, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[0.15132393 0.16293891 0.17794462 0.17635523 0.17109697 0.16034035\n",
            "   0.         0.        ]\n",
            "  [0.14574431 0.1609232  0.17782679 0.17922187 0.17381544 0.16246842\n",
            "   0.         0.        ]\n",
            "  [0.13770585 0.15791887 0.1787433  0.1844995  0.17778847 0.16334398\n",
            "   0.         0.        ]\n",
            "  [0.12979285 0.15469798 0.18028475 0.18987457 0.1813208  0.16402903\n",
            "   0.         0.        ]\n",
            "  [0.12748896 0.1531289  0.18040337 0.1909219  0.18309475 0.16496211\n",
            "   0.         0.        ]\n",
            "  [0.13022342 0.15426892 0.18016529 0.18863285 0.18180549 0.16490398\n",
            "   0.         0.        ]\n",
            "  [0.13562785 0.15644974 0.17857738 0.18357717 0.18039612 0.16537173\n",
            "   0.         0.        ]\n",
            "  [0.13965578 0.15888159 0.17841475 0.1798425  0.17851083 0.16469459\n",
            "   0.         0.        ]]], shape=(1, 8, 8), dtype=float32)\n",
            "head (8, 1, 8, 64)\n",
            "(1, 8, 512)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'custom_multi_head_attention_16' (of type CustomMultiHeadAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder Transformer Model"
      ],
      "metadata": {
        "id": "2XxhOJo7fEBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.linalg.band_part(\n",
        "        tf.ones([1,8, 8],dtype=tf.int32),-1,0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaCnK-51fHWD",
        "outputId": "6814d922-683e-4cc3-d392-a1f269d208ae"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 1 0]\n",
            "  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(Layer):\n",
        "  def __init__(self, embed_dim, latent_dim, num_heads,):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention_1=CustomMultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.attention_2=CustomMultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.dense_proj = tf.keras.Sequential(\n",
        "        [Dense(latent_dim, activation=\"relu\"),Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1=tf.keras.layers.LayerNormalization()\n",
        "    self.layernorm_2=tf.keras.layers.LayerNormalization()\n",
        "    self.layernorm_3=tf.keras.layers.LayerNormalization()\n",
        "    self.supports_masking = True\n",
        "  def call(self, inputs, encoder_outputs, enc_mask, mask=None):\n",
        "\n",
        "\n",
        "    if mask is not None:\n",
        "      causal_mask=tf.linalg.band_part(\n",
        "        tf.ones([tf.shape(inputs)[0],\n",
        "                 tf.shape(inputs)[1],\n",
        "                 tf.shape(inputs)[1]],dtype=tf.int32),-1,0)\n",
        "      mask = tf.cast(\n",
        "          mask[:,tf.newaxis, :], dtype=\"int32\")\n",
        "      enc_mask = tf.cast(\n",
        "          enc_mask[:,tf.newaxis, :], dtype=\"int32\")\n",
        "      T = tf.shape(mask)[2]\n",
        "      padding_mask = tf.repeat(mask,T,axis=1)\n",
        "      cross_attn_mask = tf.repeat(enc_mask,T,axis=1)\n",
        "      combined_mask=tf.minimum(padding_mask,causal_mask)\n",
        "\n",
        "    attention_output_1 = self.attention_1(\n",
        "        query=inputs,key=inputs,value=inputs,\n",
        "        attention_mask=combined_mask,\n",
        "\n",
        "    )\n",
        "\n",
        "    out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "    attention_output_2= self.attention_2(\n",
        "        query=out_1,key=encoder_outputs,value=encoder_outputs,\n",
        "        attention_mask=cross_attn_mask,\n",
        "\n",
        "    )\n",
        "    out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "    proj_output = self.dense_proj(out_2)\n",
        "    return self.layernorm_3(out_2 + proj_output)"
      ],
      "metadata": {
        "id": "cCgtBE3mfHTb"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_mask=mask\n",
        "decoder_outputs = TransformerDecoder(512,2048,4)(\n",
        "    emb_out,encoder_outputs,enc_mask)\n",
        "print(decoder_outputs.shape)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ptIRYyvXfHQ-"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model"
      ],
      "metadata": {
        "id": "-YcFTql4eSoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM=128\n",
        "D_FF=1024\n",
        "NUM_HEADS=8\n",
        "NUM_LAYERS = 1\n",
        "NUM_EPOCHS =10"
      ],
      "metadata": {
        "id": "MbXGwTfKeUKp"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n",
        "emb = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)\n",
        "x = emb(encoder_inputs)\n",
        "enc_mask = emb.compute_mask(encoder_inputs)\n",
        "\n",
        "for _ in range(NUM_LAYERS):\n",
        "  x=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n",
        "encoder_outputs=x\n",
        "\n",
        "decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n",
        "\n",
        "x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n",
        "for i in range(NUM_LAYERS):\n",
        "  x=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs,enc_mask)\n",
        "x=tf.keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "transformer = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w4pdheHMeUHR",
        "outputId": "260c62eb-1fc7-4d28-fbe3-8f2f46c29f1d"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:1387: UserWarning: Layer 'transformer_encoder_54' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''cannot access local variable 'padding_mask' where it is not associated with a value''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'transformer_encoder_54', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_1/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_1/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_1/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_1/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_3/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_3/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_3/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_3/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_5/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_5/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_5/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_5/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_7/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_7/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_7/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_7/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_9/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_9/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_9/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_9/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_11/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_11/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_11/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_11/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_13/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_13/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_13/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_13/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_22_15/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_self_attention_22_15/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_self_attention_22_15/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_self_attention_22_15/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "head (8, None, 64, 16)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_1/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_1/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_1/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_1/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_3/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_3/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_3/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_3/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_5/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_5/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_5/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_5/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_7/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_7/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_7/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_7/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_9/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_9/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_9/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_9/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_11/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_11/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_11/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_11/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_13/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_13/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_13/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_13/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_15/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "mask---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_15/Cast_1:0\", shape=(None, None, None), dtype=float32)\n",
            "scoringaftermasking---> Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_15/add:0\", shape=(None, 64, 64), dtype=float32)\n",
            "Tensor(\"custom_multi_head_attention_9_1/custom_self_attention_22_15/mul_1:0\", shape=(None, 64, 64), dtype=float32)\n",
            "head (8, None, 64, 16)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_self_attention_23_1/truediv:0\", shape=(None, 64, 64), dtype=float32)\n",
            "hello (None, 64, 16)\n",
            "score---> Tensor(\"custom_multi_head_attention_10_1/custom_self_attention_23_1/truediv:0\", shape=(None, 64, 64), dtype=float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling TransformerDecoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'transformer_decoder_24' (of type TransformerDecoder). Either the `TransformerDecoder.call()` method is incorrect, or you need to implement the `TransformerDecoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling CustomSelfAttention.call().\n\n\u001b[1mNone values not supported.\u001b[0m\n\nArguments received by CustomSelfAttention.call():\n  • query=tf.Tensor(shape=(None, 64, 16), dtype=float32)\n  • key=tf.Tensor(shape=(None, 64, 16), dtype=float32)\n  • value=tf.Tensor(shape=(None, 64, 16), dtype=float32)\n  • masking=None\u001b[0m\n\nArguments received by TransformerDecoder.call():\n  • args=('<KerasTensor shape=(None, 64, 128), dtype=float32, sparse=False, name=keras_tensor_288>', '<KerasTensor shape=(None, 64, 128), dtype=float32, sparse=False, name=keras_tensor_286>', '<KerasTensor shape=(None, None), dtype=float32, sparse=False, name=keras_tensor_281>')\n  • kwargs=<class 'inspect._empty'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-288-cbf7605dfd06>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFRENCH_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTransformerDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD_FF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_HEADS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-282-90440a389125>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, encoder_outputs, enc_mask, mask)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Combined Mask (Padding ∩ Causal):\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         attention_output_1 = self.attention_1(\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-274-b7ce5121f214>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, attention_mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hello\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       head=self.self_attention(self.dense_q[i](query),\n\u001b[0m\u001b[1;32m     18\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-272-aefdd10da084>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, masking)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score--->'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m######## masking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask--->'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mscore\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling TransformerDecoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'transformer_decoder_24' (of type TransformerDecoder). Either the `TransformerDecoder.call()` method is incorrect, or you need to implement the `TransformerDecoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling CustomSelfAttention.call().\n\n\u001b[1mNone values not supported.\u001b[0m\n\nArguments received by CustomSelfAttention.call():\n  • query=tf.Tensor(shape=(None, 64, 16), dtype=float32)\n  • key=tf.Tensor(shape=(None, 64, 16), dtype=float32)\n  • value=tf.Tensor(shape=(None, 64, 16), dtype=float32)\n  • masking=None\u001b[0m\n\nArguments received by TransformerDecoder.call():\n  • args=('<KerasTensor shape=(None, 64, 128), dtype=float32, sparse=False, name=keras_tensor_288>', '<KerasTensor shape=(None, 64, 128), dtype=float32, sparse=False, name=keras_tensor_286>', '<KerasTensor shape=(None, None), dtype=float32, sparse=False, name=keras_tensor_281>')\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jPHPetnAeUEk"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple GRU"
      ],
      "metadata": {
        "id": "vIYvvNx0msXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_UNITS =256"
      ],
      "metadata": {
        "id": "fkgQ1USc0n9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ENCODER (english input)\n",
        "input = Input(shape=(ENGLISH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_1\")  # English sentence as input\n",
        "x = Embedding(VOCAB_SIZE, EMBEDDING_DIM)(input)                                 # Convert words to dense vector form\n",
        "encoded_input = Bidirectional(GRU(NUM_UNITS))(x)                                # Understand context from both directions\n",
        "\n",
        "### DECODER (french output)\n",
        "shifted_target = Input(shape=(FRENCH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_2\")  # French sentence with 'start' token\n",
        "x = Embedding(VOCAB_SIZE, EMBEDDING_DIM)(shifted_target)                                # Convert French words to dense vectors\n",
        "x = GRU(NUM_UNITS * 2, return_sequences=True)(x, initial_state=encoded_input)           # Generate output using English context\n",
        "\n",
        "### OUTPUT\n",
        "x = Dropout(0.5)(x)                                              # Prevent overfitting\n",
        "target = Dense(VOCAB_SIZE, activation=\"softmax\")(x)              # Predict the next French word\n",
        "seq2seq_gru = Model([input, shifted_target], target)             # Build the full model\n",
        "seq2seq_gru.summary()                                            # Show model architecture\n"
      ],
      "metadata": {
        "id": "ZYUYNgXPeBOE",
        "outputId": "42798a9b-0e69-455b-d34d-762493c2f066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m6,000,000\u001b[0m │ input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m6,000,000\u001b[0m │ input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m857,088\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,250,304\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m20000\u001b[0m) │ \u001b[38;5;34m10,260,000\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │ input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │ input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">857,088</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,250,304</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,260,000</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,367,392\u001b[0m (92.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,367,392</span> (92.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,367,392\u001b[0m (92.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,367,392</span> (92.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Reference : https://www.tensorflow.org/api_docs/python/tf/keras/Metric"
      ],
      "metadata": {
        "id": "3fz8TDqv8mQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BLEU(tf.keras.metrics.Metric): #custom class inherits from Metrics class\n",
        "\n",
        "    def __init__(self, name='bleu_score'):\n",
        "        super(BLEU,self).__init__(name=name)\n",
        "        self.bleu_score =0\n",
        "\n",
        "    @tf.function #decorator added to update_state function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred, axis=-1)\n",
        "      self.bleu_score=0\n",
        "\n",
        "      #zip up the pair of y_true and y_pred\n",
        "      for i, j in zip(y_true,y_pred):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches = 0\n",
        "\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if j[q]==word:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "        self.bleu_score+= total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "      return self.bleu_score/BATCH_SIZE\n"
      ],
      "metadata": {
        "id": "v9QSAFIk8Dpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### example illustration to show how boolean works\n",
        "# j = tf.constant([2,3,4,5,0,0])\n",
        "# print([False if y==2 else True for y in range(len(j))])\n",
        "# j = tf.boolean_mask(j,[False if y==2 else True for y in range(len(j))])\n",
        "# print(j)"
      ],
      "metadata": {
        "id": "q4G0aVIR_w9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scheduler"
      ],
      "metadata": {
        "id": "bR7W4ec_JKbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps):\n",
        "    super(Scheduler, self).__init__()\n",
        "    self.d_model = tf.cast(d_model, tf.float64)\n",
        "    self.warmup_steps = tf.cast(warmup_steps, dtype=tf.float64)\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float64)\n",
        "    #copied from paper\n",
        "    return (self.d_model**(-0.5))*tf.math.minimum(step**(-0.5), step * (self.warmup_steps ** -1.5))"
      ],
      "metadata": {
        "id": "COfJFxV2JHWN"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WARM_UP_STEPS = 4000\n",
        "lr_scheduled = Scheduler(EMBEDDING_DIM, WARM_UP_STEPS)"
      ],
      "metadata": {
        "id": "GAhZI57iJMGp"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ],
      "metadata": {
        "id": "aglJyXLhGNK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "transformer.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = Adam(lr_scheduled, beta_1=0.9, beta_2=0.98, epsilon=1e-9),)\n",
        "    #metrics=[BLEU()],\n",
        "    #run_eagerly=True)"
      ],
      "metadata": {
        "id": "z32_OctceBLb"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/nlp/translation/gru1.keras'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,)"
      ],
      "metadata": {
        "id": "iDNKmKnZvAJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model\n",
        "history=transformer.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10)"
      ],
      "metadata": {
        "id": "bTqkgbKgeBIz",
        "outputId": "5efa75a4-9870-4f85-dc12-8f5c4dba23ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1296s\u001b[0m 456ms/step - loss: 0.5153 - val_loss: 0.7469\n",
            "Epoch 2/10\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 0.5670"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-245-ad3dddbf08d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history=transformer.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     epochs=10)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    393\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                     )\n\u001b[0;32m--> 395\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    396\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_evaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MIxvQDF4eBGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zYQEvEiteBDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "o7ZU4sMi087i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq_gru.evaluate(val_dataset)"
      ],
      "metadata": {
        "id": "clQxKilx0-EI",
        "outputId": "f35ad37f-ed61-4ab0-c708-df04be4e0a1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     70/Unknown \u001b[1m116s\u001b[0m 1s/step - bleu_score: 0.0000e+00 - loss: 1.1114"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ad8d4a1988ca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq2seq_gru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_evaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mmulti_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 return tf.experimental.Optional.from_value(\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m    115\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         )\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# The default implementation does not use `x`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-9dcd5e0b5cb4>\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/tensor_getitem_override.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    230\u001b[0m           \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m           \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m           array_ops_stack.stack(strides))\n\u001b[0m\u001b[1;32m    233\u001b[0m       \u001b[0;31m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;31m# same dtypes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_ops_stack.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    730\u001b[0m   \u001b[0;31m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m   \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[1;32m    733\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepted_result_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_tensor_conversion.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    277\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m ) -> ops._EagerTensorBase:\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "RFX8_wHp1COa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word ={x:y for x,y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "N721qg5ZzXe_",
        "outputId": "d8e64f17-a1f9-4500-e97a-8e5becc35f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'french_vectorize_layer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-da95a2457b19>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m index_to_word ={x:y for x,y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                    french_vectorize_layer.get_vocabulary())}\n",
            "\u001b[0;31mNameError\u001b[0m: name 'french_vectorize_layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word"
      ],
      "metadata": {
        "id": "q5ra65pu2pyd",
        "outputId": "5303ea5b-e8e8-454f-97c6-6b8a0f175655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'index_to_word' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ea39bee7d17c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'index_to_word' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def  translator(english_sentence):\n",
        "  tokenized_english_sentence = english_vectorize_layer([english_sentence])\n",
        "  shifted_target = 'starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "     tokenized_shifted_target = french_vectorize_layer([shifted_target])\n",
        "     output = seq2seq_gru.predict([tokenized_english_sentence, tokenized_shifted_target])\n",
        "     french_word_index = tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "     current_word=index_to_word[french_word_index]\n",
        "     if current_word==\"endtoken\":\n",
        "      break\n",
        "      shifted_target += ' '+current_word\n",
        "  return shifted_target[11:]"
      ],
      "metadata": {
        "id": "fyMmQkgn1DOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\"what makes you think that is not true?\").shape"
      ],
      "metadata": {
        "id": "BF8Kc_7izMC7",
        "outputId": "00552d21-ba08-43e0-a52a-50dd9cd4c98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-250-43d78d6a83a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"what makes you think that is not true?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pull top 5 volcabulary from english\n",
        "vocab = english_vectorize_layer.get_vocabulary()\n",
        "print([str(word) for word in vocab[:5]])"
      ],
      "metadata": {
        "id": "e1TLvieav93H",
        "outputId": "24bb4ba6-7133-42ad-eac0-725e3176c9d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'i', 'you', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pull top 5 volcabulary from english\n",
        "vocab = french_vectorize_layer.get_vocabulary()\n",
        "print([str(word) for word in vocab[:5]])"
      ],
      "metadata": {
        "id": "PozNKdWvv9zy",
        "outputId": "c731254c-6c5a-4ca3-89a2-34cb714ebc75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'starttoken', 'endtoken', 'je']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index={y:x for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "QpSEXPCsv9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['football']"
      ],
      "metadata": {
        "id": "UjH-vVAx3X5P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}